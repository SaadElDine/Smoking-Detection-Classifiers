{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcc510c",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b983c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeca551",
   "metadata": {},
   "source": [
    "# Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19da70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_valid = pd.read_csv(\"X_valid.csv\")\n",
    "X_test = pd.read_csv(\"X_test.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "y_valid = pd.read_csv(\"y_valid.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "# Reshape the target arrays\n",
    "y_train = np.ravel(y_train)\n",
    "y_val = np.ravel(y_valid)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f194a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data - X_train shape: (101923, 25)\n",
      "Training Data - y_train shape: (101923,)\n",
      "Cross Validation Data - X_val shape: (25481, 25)\n",
      "Cross Validation Data - y_val shape: (25481, 1)\n",
      "Testing Data - X_test shape: (31852, 25)\n",
      "Testing Data - y_test shape: (31852,)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes of the resulting sets\n",
    "print(\"Training Data - X_train shape:\", X_train.shape)\n",
    "print(\"Training Data - y_train shape:\", y_train.shape)\n",
    "print(\"Cross Validation Data - X_val shape:\", X_valid.shape)\n",
    "print(\"Cross Validation Data - y_val shape:\", y_valid.shape)\n",
    "print(\"Testing Data - X_test shape:\", X_test.shape)\n",
    "print(\"Testing Data - y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7e204",
   "metadata": {},
   "source": [
    "# Basic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57870f",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the base classifier (Decision Tree in this case)\n",
    "#base_classifier = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "# Initialize the BaggingClassifier\n",
    "bagging_classifier = BaggingClassifier(n_estimators=200)\n",
    "\n",
    "# Train the BaggingClassifier on the training data\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_valid_pred = bagging_classifier.predict(X_valid)\n",
    "\n",
    "# Evaluate the performance on the validation set\n",
    "accuracy_valid = accuracy_score(y_valid, y_valid_pred)\n",
    "print(f\"Accuracy on the validation set: {accuracy_valid:.2%}\")\n",
    "\n",
    "# You can also print additional evaluation metrics if needed\n",
    "print(\"\\nClassification Report on Validation Set:\")\n",
    "print(classification_report(y_valid, y_valid_pred))\n",
    "\n",
    "# Confusion Matrix on Validation Set\n",
    "conf_matrix_valid = confusion_matrix(y_valid, y_valid_pred)\n",
    "print(\"\\nConfusion Matrix on Validation Set:\")\n",
    "print(conf_matrix_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52520df",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the base classifier (Decision Tree in this case)\n",
    "#base_classifier = DecisionTreeClassifier(random_state=random_seed)\n",
    "\n",
    "# Initialize the AdaBoostClassifier\n",
    "adaboost_classifier = AdaBoostClassifier(n_estimators=200)\n",
    "\n",
    "# Train the AdaBoostClassifier on the training data\n",
    "adaboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_valid_pred_boosting = adaboost_classifier.predict(X_valid)\n",
    "\n",
    "# Evaluate the performance on the validation set\n",
    "accuracy_valid_boosting = accuracy_score(y_valid, y_valid_pred_boosting)\n",
    "print(f\"Accuracy on the validation set (Boosting): {accuracy_valid_boosting:.2%}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nClassification Report on Validation Set (Boosting):\")\n",
    "print(classification_report(y_valid, y_valid_pred_boosting))\n",
    "\n",
    "# Confusion Matrix on Validation Set\n",
    "conf_matrix_valid_boosting = confusion_matrix(y_valid, y_valid_pred_boosting)\n",
    "print(\"\\nConfusion Matrix on Validation Set (Boosting):\")\n",
    "print(conf_matrix_valid_boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a997b1af",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "random_forest_classifier = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# Train the RandomForestClassifier on the training data\n",
    "random_forest_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the validation set\n",
    "y_valid_pred_forest = random_forest_classifier.predict(X_valid)\n",
    "\n",
    "# Evaluate the performance on the validation set\n",
    "accuracy_valid_forest = accuracy_score(y_valid, y_valid_pred_forest)\n",
    "print(f\"Accuracy on the validation set (Random Forests): {accuracy_valid_forest:.2%}\")\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(\"\\nClassification Report on Validation Set (Random Forests):\")\n",
    "print(classification_report(y_valid, y_valid_pred_forest))\n",
    "\n",
    "# Confusion Matrix on Validation Set\n",
    "conf_matrix_valid_forest = confusion_matrix(y_valid, y_valid_pred_forest)\n",
    "print(\"\\nConfusion Matrix on Validation Set (Random Forests):\")\n",
    "print(conf_matrix_valid_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf1f8e",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a76758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# Function for model evaluation\n",
    "def evaluate_model(model, X, y, dataset_name):\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(f\"Accuracy on {dataset_name}: {accuracy:.2%}\")\n",
    "\n",
    "    # Additional metrics\n",
    "    print(f\"\\nClassification Report on {dataset_name}:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "    print(f\"\\nConfusion Matrix on {dataset_name}:\")\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76025765",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging with Hyperparameter Tuning (Grid Search)\n",
    "#bagging_base_classifier = DecisionTreeClassifier(random_state=random_seed)\n",
    "bagging_model = BaggingClassifier(random_state=42)\n",
    "\n",
    "bagging_param_grid = {\n",
    "    'n_estimators': [200],\n",
    "    'max_samples': [0.5],\n",
    "    'max_features': [0.7],\n",
    "}\n",
    "\n",
    "bagging_grid_search = GridSearchCV(bagging_model, param_grid=bagging_param_grid, cv=5)\n",
    "bagging_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters for Bagging:\")\n",
    "print(bagging_grid_search.best_params_)\n",
    "\n",
    "# Evaluate Bagging on Validation Set\n",
    "evaluate_model(bagging_grid_search, X_valid, y_valid, \"Validation Set (Bagging)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "513c263c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Boosting:\n",
      "{'learning_rate': 1.0, 'n_estimators': 500}\n",
      "Accuracy on Validation Set (Boosting): 76.72%\n",
      "\n",
      "Classification Report on Validation Set (Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78     14415\n",
      "           1       0.69      0.83      0.76     11066\n",
      "\n",
      "    accuracy                           0.77     25481\n",
      "   macro avg       0.77      0.77      0.77     25481\n",
      "weighted avg       0.78      0.77      0.77     25481\n",
      "\n",
      "\n",
      "Confusion Matrix on Validation Set (Boosting):\n",
      "[[10356  4059]\n",
      " [ 1872  9194]]\n"
     ]
    }
   ],
   "source": [
    "# Boosting with Hyperparameter Tuning (Grid Search)\n",
    "#boosting_base_classifier = DecisionTreeClassifier(random_state=random_seed)\n",
    "boosting_model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "boosting_param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 500],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "boosting_grid_search = GridSearchCV(boosting_model, param_grid=boosting_param_grid, cv=5)\n",
    "boosting_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Hyperparameters for Boosting:\")\n",
    "print(boosting_grid_search.best_params_)\n",
    "\n",
    "# Evaluate Boosting on Validation Set\n",
    "evaluate_model(boosting_grid_search, X_valid, y_valid, \"Validation Set (Boosting)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db057d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Random Forests:\n",
      "{'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 500}\n",
      "Accuracy on Validation Set (Random Forests): 76.56%\n",
      "\n",
      "Classification Report on Validation Set (Random Forests):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78     14415\n",
      "           1       0.69      0.83      0.75     11066\n",
      "\n",
      "    accuracy                           0.77     25481\n",
      "   macro avg       0.77      0.77      0.77     25481\n",
      "weighted avg       0.78      0.77      0.77     25481\n",
      "\n",
      "\n",
      "Confusion Matrix on Validation Set (Random Forests):\n",
      "[[10346  4069]\n",
      " [ 1903  9163]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forests with Hyperparameter Tuning (Grid Search)\n",
    "forest_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "forest_param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "forest_grid_search = GridSearchCV(forest_model, param_grid=forest_param_grid, cv=5)\n",
    "forest_grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Hyperparameters for Random Forests:\")\n",
    "print(forest_grid_search.best_params_)\n",
    "\n",
    "# Evaluate Random Forests on Validation Set\n",
    "evaluate_model(forest_grid_search, X_valid, y_valid, \"Validation Set (Random Forests)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6b0777",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fe609a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Bagging (Randomized Search):\n",
      "{'n_estimators': 200, 'max_samples': 0.5, 'max_features': 0.7}\n",
      "Accuracy on Validation Set (Bagging - Randomized): 76.45%\n",
      "\n",
      "Classification Report on Validation Set (Bagging - Randomized):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78     14415\n",
      "           1       0.70      0.81      0.75     11066\n",
      "\n",
      "    accuracy                           0.76     25481\n",
      "   macro avg       0.77      0.77      0.76     25481\n",
      "weighted avg       0.77      0.76      0.77     25481\n",
      "\n",
      "\n",
      "Confusion Matrix on Validation Set (Bagging - Randomized):\n",
      "[[10484  3931]\n",
      " [ 2071  8995]]\n"
     ]
    }
   ],
   "source": [
    "# Bagging with Hyperparameter Tuning (Randomized Search)\n",
    "bagging_randomized_search = RandomizedSearchCV(bagging_model, param_distributions=bagging_param_grid, n_iter=10, cv=5, random_state=42)\n",
    "bagging_randomized_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Hyperparameters for Bagging (Randomized Search):\")\n",
    "print(bagging_randomized_search.best_params_)\n",
    "\n",
    "# Evaluate Bagging on Validation Set\n",
    "evaluate_model(bagging_randomized_search, X_valid, y_valid, \"Validation Set (Bagging - Randomized)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1758aa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Boosting (Randomized Search):\n",
      "{'n_estimators': 500, 'learning_rate': 1.0}\n",
      "Accuracy on Validation Set (Boosting - Randomized): 76.72%\n",
      "\n",
      "Classification Report on Validation Set (Boosting - Randomized):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78     14415\n",
      "           1       0.69      0.83      0.76     11066\n",
      "\n",
      "    accuracy                           0.77     25481\n",
      "   macro avg       0.77      0.77      0.77     25481\n",
      "weighted avg       0.78      0.77      0.77     25481\n",
      "\n",
      "\n",
      "Confusion Matrix on Validation Set (Boosting - Randomized):\n",
      "[[10356  4059]\n",
      " [ 1872  9194]]\n"
     ]
    }
   ],
   "source": [
    "# Boosting with Hyperparameter Tuning (Randomized Search)\n",
    "boosting_randomized_search = RandomizedSearchCV(boosting_model, param_distributions=boosting_param_grid, n_iter=10, cv=5, random_state=42)\n",
    "boosting_randomized_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Hyperparameters for Boosting (Randomized Search):\")\n",
    "print(boosting_randomized_search.best_params_)\n",
    "\n",
    "# Evaluate Boosting on Validation Set\n",
    "evaluate_model(boosting_randomized_search, X_valid, y_valid, \"Validation Set (Boosting - Randomized)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa4295a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for Random Forests (Randomized Search):\n",
      "{'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 20}\n",
      "Accuracy on Validation Set (Random Forests - Randomized): 76.56%\n",
      "\n",
      "Classification Report on Validation Set (Random Forests - Randomized):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78     14415\n",
      "           1       0.69      0.83      0.75     11066\n",
      "\n",
      "    accuracy                           0.77     25481\n",
      "   macro avg       0.77      0.77      0.77     25481\n",
      "weighted avg       0.78      0.77      0.77     25481\n",
      "\n",
      "\n",
      "Confusion Matrix on Validation Set (Random Forests - Randomized):\n",
      "[[10346  4069]\n",
      " [ 1903  9163]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forests with Hyperparameter Tuning (Randomized Search)\n",
    "forest_randomized_search = RandomizedSearchCV(forest_model, param_distributions=forest_param_grid, n_iter=10, cv=5, random_state=42)\n",
    "forest_randomized_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Hyperparameters for Random Forests (Randomized Search):\")\n",
    "print(forest_randomized_search.best_params_)\n",
    "\n",
    "# Evaluate Random Forests on Validation Set\n",
    "evaluate_model(forest_randomized_search, X_valid, y_valid, \"Validation Set (Random Forests - Randomized)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "673645a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set (Bagging): 77.00%\n",
      "\n",
      "Classification Report on Test Set (Bagging):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78     17936\n",
      "           1       0.70      0.82      0.76     13916\n",
      "\n",
      "    accuracy                           0.77     31852\n",
      "   macro avg       0.77      0.78      0.77     31852\n",
      "weighted avg       0.78      0.77      0.77     31852\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Set (Bagging):\n",
      "[[13181  4755]\n",
      " [ 2572 11344]]\n",
      "Accuracy on Test Set (Boosting): 77.00%\n",
      "\n",
      "Classification Report on Test Set (Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78     17936\n",
      "           1       0.70      0.83      0.76     13916\n",
      "\n",
      "    accuracy                           0.77     31852\n",
      "   macro avg       0.77      0.78      0.77     31852\n",
      "weighted avg       0.78      0.77      0.77     31852\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Set (Boosting):\n",
      "[[12996  4940]\n",
      " [ 2387 11529]]\n",
      "Accuracy on Test Set (Random Forests): 77.03%\n",
      "\n",
      "Classification Report on Test Set (Random Forests):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78     17936\n",
      "           1       0.70      0.83      0.76     13916\n",
      "\n",
      "    accuracy                           0.77     31852\n",
      "   macro avg       0.77      0.78      0.77     31852\n",
      "weighted avg       0.78      0.77      0.77     31852\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Set (Random Forests):\n",
      "[[12973  4963]\n",
      " [ 2353 11563]]\n"
     ]
    }
   ],
   "source": [
    "# Final System: Choose the Best Performing Models\n",
    "best_bagging_model = bagging_randomized_search.best_estimator_\n",
    "best_boosting_model = boosting_randomized_search.best_estimator_\n",
    "best_forest_model = forest_randomized_search.best_estimator_\n",
    "\n",
    "# Evaluate on Test Set\n",
    "evaluate_model(best_bagging_model, X_test, y_test, \"Test Set (Bagging)\")\n",
    "evaluate_model(best_boosting_model, X_test, y_test, \"Test Set (Boosting)\")\n",
    "evaluate_model(best_forest_model, X_test, y_test, \"Test Set (Random Forests)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68669e",
   "metadata": {},
   "source": [
    "#  Bayesian method: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200d94b",
   "metadata": {},
   "source": [
    "## Tree-structured Parzen Estimator (TPE) algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33364cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, Trials, fmin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "random_seed = 7370 + 7524\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [50, 100, 150]),\n",
    "    'max_depth': hp.choice('max_depth', [None, 10, 20]),\n",
    "    'min_samples_split': hp.choice('min_samples_split', [2, 5, 10]),\n",
    "    'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 4]),\n",
    "}\n",
    "\n",
    "# Objective function for hyperopt to minimize (negative accuracy)\n",
    "def objective(params):\n",
    "    model = RandomForestClassifier(random_state=random_seed, **params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
    "    return -score  # Minimize negative accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Bayesian optimization with TPE algorithm\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, trials=trials, rstate=np.random.RandomState(random_seed))\n",
    "\n",
    "# Get the best hyperparameters found by Bayesian optimization\n",
    "best_params = space_eval(space, best)\n",
    "print(\"Best Hyperparameters for Random Forests (Bayesian Optimization):\")\n",
    "print(best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters on the entire training set\n",
    "best_forest_model_bayesian = RandomForestClassifier(random_state=random_seed, **best_params)\n",
    "best_forest_model_bayesian.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "evaluate_model(best_forest_model_bayesian, X_test, y_test, \"Test Set (Random Forests - Bayesian Optimization)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2660bb2",
   "metadata": {},
   "source": [
    "## (Tree-structured Parzen Estimator (TPE) algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define the search space for hyperparameters\n",
    "space = [\n",
    "    Integer(10 600, name='n_estimators'),\n",
    "    Integer(1, 20, name='max_depth'),\n",
    "    Integer(1, 30 name='min_samples_split'),\n",
    "    Integer(1, 30 name='min_samples_leaf')\n",
    "]\n",
    "\n",
    "# Objective function for skopt to minimize (negative accuracy)\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    model = RandomForestClassifier(random_state=42, **params)\n",
    "    score = cross_val_score(model, X_train, y_train, cv=5).mean()\n",
    "    return -score  # Minimize negative accuracy\n",
    "\n",
    "# Perform hyperparameter tuning using Gaussian Process optimization\n",
    "result = gp_minimize(objective, space, n_calls=50, random_state=42)\n",
    "\n",
    "# Get the best hyperparameters found by Gaussian Process optimization\n",
    "best_params = dict(zip(['n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf'], result.x))\n",
    "print(\"Best Hyperparameters for Random Forests (Gaussian Process Optimization):\")\n",
    "print(best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters on the entire training set\n",
    "best_forest_model_gp = RandomForestClassifier(random_state=42, **best_params)\n",
    "best_forest_model_gp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "evaluate_model(best_forest_model_gp, X_test, y_test, \"Test Set (Random Forests - Gaussian Process Optimization)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7166c6",
   "metadata": {},
   "source": [
    "# Final System Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc189ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation of Best Bagging Model on Test Set:\n",
      "Accuracy on Test Set (Best Bagging): 77.00%\n",
      "\n",
      "Classification Report on Test Set (Best Bagging):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78     17936\n",
      "           1       0.70      0.82      0.76     13916\n",
      "\n",
      "    accuracy                           0.77     31852\n",
      "   macro avg       0.77      0.78      0.77     31852\n",
      "weighted avg       0.78      0.77      0.77     31852\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Set (Best Bagging):\n",
      "[[13181  4755]\n",
      " [ 2572 11344]]\n",
      "\n",
      "Evaluation of Best Boosting Model on Test Set:\n",
      "Accuracy on Test Set (Best Boosting): 77.00%\n",
      "\n",
      "Classification Report on Test Set (Best Boosting):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78     17936\n",
      "           1       0.70      0.83      0.76     13916\n",
      "\n",
      "    accuracy                           0.77     31852\n",
      "   macro avg       0.77      0.78      0.77     31852\n",
      "weighted avg       0.78      0.77      0.77     31852\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Set (Best Boosting):\n",
      "[[12996  4940]\n",
      " [ 2387 11529]]\n",
      "\n",
      "Evaluation of Best Random Forest Model on Test Set:\n",
      "Accuracy on Test Set (Best Random Forest): 77.03%\n",
      "\n",
      "Classification Report on Test Set (Best Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78     17936\n",
      "           1       0.70      0.83      0.76     13916\n",
      "\n",
      "    accuracy                           0.77     31852\n",
      "   macro avg       0.77      0.78      0.77     31852\n",
      "weighted avg       0.78      0.77      0.77     31852\n",
      "\n",
      "\n",
      "Confusion Matrix on Test Set (Best Random Forest):\n",
      "[[12973  4963]\n",
      " [ 2353 11563]]\n",
      "\n",
      "Comparison of Model Performances on Test Set:\n",
      "Accuracy - Bagging: 77.00%\n",
      "Accuracy - Boosting: 77.00%\n",
      "Accuracy - Random Forest: 77.03%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Best Bagging Model on Test Set\n",
    "print(\"\\nEvaluation of Best Bagging Model on Test Set:\")\n",
    "evaluate_model(best_bagging_model, X_test, y_test, \"Test Set (Best Bagging)\")\n",
    "\n",
    "# Evaluate Best Boosting Model on Test Set\n",
    "print(\"\\nEvaluation of Best Boosting Model on Test Set:\")\n",
    "evaluate_model(best_boosting_model, X_test, y_test, \"Test Set (Best Boosting)\")\n",
    "\n",
    "# Evaluate Best Random Forest Model on Test Set\n",
    "print(\"\\nEvaluation of Best Random Forest Model on Test Set:\")\n",
    "evaluate_model(best_forest_model, X_test, y_test, \"Test Set (Best Random Forest)\")\n",
    "\n",
    "# Compare Models\n",
    "accuracy_bagging = accuracy_score(y_test, best_bagging_model.predict(X_test))\n",
    "accuracy_boosting = accuracy_score(y_test, best_boosting_model.predict(X_test))\n",
    "accuracy_forest = accuracy_score(y_test, best_forest_model.predict(X_test))\n",
    "\n",
    "print(\"\\nComparison of Model Performances on Test Set:\")\n",
    "print(f\"Accuracy - Bagging: {accuracy_bagging:.2%}\")\n",
    "print(f\"Accuracy - Boosting: {accuracy_boosting:.2%}\")\n",
    "print(f\"Accuracy - Random Forest: {accuracy_forest:.2%}\")\n",
    "\n",
    "best_model = max([(accuracy_bagging, 'Bagging'), (accuracy_boosting, 'Boosting'), (accuracy_forest, 'Random Forest')],\n",
    "                 key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2d6f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best-performing model on the test set is: Random Forest with an accuracy of 77.06%\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nThe best-performing model on the test set is: {best_model[1]} with an accuracy of {best_model[0]:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
